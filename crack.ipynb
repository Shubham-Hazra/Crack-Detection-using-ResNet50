{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b555c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp crack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d482275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52d52810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "# Unzip the contents\n",
    "#!unzip concrete_crack_images_for_classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c330cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Import the relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b7a40716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "# Create the dataset class\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self,transform = None,train = True):\n",
    "        positive_file_path=\"./Positive\"\n",
    "        negative_file_path=\"./Negative\"\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "        positive_files.sort()\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "        negative_files.sort()\n",
    "\n",
    "        num_samples = len(negative_files)+len(positive_files)\n",
    "        \n",
    "        self.all_files=[None]*num_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([num_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:3]\n",
    "            self.Y=self.Y[0:3]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)\n",
    "            \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8853b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Define the datasets and transforms\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "input_size = 224\n",
    "composed = transform =transforms.Compose([ transforms.RandomResizedCrop(input_size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(), \n",
    "                                          transforms.Normalize(mean, std)])\n",
    "\n",
    "dataset_train=dataset(transform=transform,train=True)\n",
    "dataset_val=dataset(transform=transform,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5ec3bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Set the parameters\n",
    "torch.manual_seed(0)\n",
    "learning_rate = 0.1\n",
    "momentum = 0.1\n",
    "batch_size = 1000\n",
    "test_batch_size = 5000\n",
    "epochs = 5\n",
    "num_classes = 2\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "80cda553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "# Initilize the pretrained model and optimizer and loss\n",
    "# Using resnet50\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "model.fc = nn.Linear(2048,num_classes)\n",
    "trainable_params = []\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        trainable_params.append(param)\n",
    "\n",
    "optimizer = torch.optim.SGD(trainable_params,lr = learning_rate,momentum = momentum)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5eb3325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 6.6970e-03, -6.0678e-03,  1.8278e-02,  ...,  1.2842e-02,\n",
       "          -2.0258e-02,  9.5235e-05],\n",
       "         [-2.0734e-02, -1.2677e-02, -1.2411e-02,  ...,  1.0510e-02,\n",
       "           3.4056e-04,  1.4999e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0218, 0.0203], requires_grad=True)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ca553b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [211]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     _, yhat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y_pred\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m     correct_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (yhat \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 28\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m correct_train \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     29\u001b[0m train_accuracy_list\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[0;32m     30\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "#Define the dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_val,batch_size=test_batch_size)\n",
    "\n",
    "#Train the model\n",
    "\n",
    "loss = 0\n",
    "accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct_train = 0\n",
    "    loss = 0\n",
    "    i=0\n",
    "    for x,y in train_loader:\n",
    "        print(i)\n",
    "        i+=1\n",
    "#         model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss_val = criterion(y_pred,y)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_val\n",
    "        _, yhat = torch.max(y_pred.data, 1)\n",
    "        correct_train += (yhat == y).sum().item()\n",
    "    accuracy = correct_train / len*100\n",
    "    train_accuracy_list.append(accuracy)\n",
    "    loss_list.append(loss.data)\n",
    "    correct_test = 0\n",
    "    for x,y in test_loader:\n",
    "        model.eval()\n",
    "        y_pred = model(x)\n",
    "        _, yhat = torch.max(y_pred.data, 1)\n",
    "        correct_test += (yhat == y).sum().item()\n",
    "    accuracy = correct_test / len(test_dataset)*100\n",
    "    test_accuracy_list.append(accuracy)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdcd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Plot the loss and accuracy\n",
    "plt.plot(train_accuracy_list, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(test_accuracy_list, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(loss_list, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0555f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "nbdev.export.nb_export('crack.ipynb','crack.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bc87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
